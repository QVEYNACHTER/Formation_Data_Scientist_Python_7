Ce projet est séparé en deux parties qui s'inscrivent dans la continuité des deux projets précédents.

- Première partie : Il s'agit d'apporter des améliorations au dashboard créé dans le dernier projet. En guise de rappel, dans le projet en question j'ai calculé la probabilité qu'un client rembourse son crédit afin de l'accorder ou non en développant un algorithme de classification s'appuyant sur des données comportementales ainsi que des données d'autres institutions financières. Dans ce projet, on m'informe que les clients demandent plus de transparence vis-à-vis des décisions d'octroi de crédit. J'ai donc ajouté davantage d'informations au dashboard afin que les chargés de relation client puissent satisfaire cette demande. Notamment la possibilité de sélectionner les features qui ont le plus de poids dans la prise de décision (positivement et négativement) dans des listes déroulantes, et de les comparer avec la distribution du reste de la clientèle pour cette feature. J'ai également pris soin de prendre en compte le besoin des personnes en situation de handicap dans la réalisation des graphiques, en augmentant considérablement la taille de la police pour les malvoyants ainsi qu'en choisissant des couleurs très contrastées pour les daltoniens.

- Seconde partie : Il s'agit de la réalisation d'un état de l'art sur une technique récente de modélisation de données texte, testée et comparée à une approche plus basique réalisée dans l'avant-dernier projet. En guise de rappel, dans le projet en question j'ai effectué une étude de faisabilité d'un moteur de classification automatique à partir de données textuelles (BERT et USE) ou images (CNN/Transfer learning à partir du modèle VGG-16). J'ai décidé de me focaliser sur le modèle BERT et de le comparer à une de ses variantes RoBERTa, j'ai retenu les modèles "base" ainsi que les modèles "large". J'ai donc suivi la même marche à suivre que précédemment : extraction de features, réduction de dimensionnalité (t-SNE), choisi l'ARI comme métrique d'évaluation. J'ai cependant décidé de modifier un peu les choses au moment de choisir le modèle de clustering. Dans l'ancien projet je m'étais contenté de k-means, mais comme j'ai obtenu ici des résultats assez décevants, j'ai tenté un CAH, ce qui s'est révélé être un excellent choix puisque RoBERTa_large a obtenu des résultats excellents par rapport au reste de la compétition. Cela dit il y a un certain nombre de limites et d'améliorations possibles que je ne manque pas de souligner pour conclure cette présentation.
